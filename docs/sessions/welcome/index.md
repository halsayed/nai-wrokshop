# Welcome & Introduction

## Session Overview

Welcome to the "Empowering Infrastructure Teams with GenAI" workshop! This session will set the stage for our day of exploration and hands-on learning with AI technologies on Nutanix infrastructure.

## Workshop Objectives

By the end of today's workshop, you will:

- Understand the core concepts behind Large Language Models (LLMs) and Generative AI
- Learn how to deploy and manage LLMs on Nutanix infrastructure
- Build a functional AI-powered chatbot with document understanding capabilities
- Integrate AI tools into your development workflow
- Create automated processes for infrastructure management using AI
- Gain practical experience through hands-on labs

## About Nutanix AI Infrastructure (NAI)

Nutanix AI Infrastructure (NAI) is designed to simplify the deployment and management of AI workloads at scale. It provides:

- Streamlined deployment of AI/ML frameworks
- Simplified management of GPU resources
- Optimized infrastructure for LLM inferencing
- Integration with Kubernetes for containerized AI applications
- Enterprise-grade security and governance

## Workshop Format

Each session will follow this format:

1. **Theory component**: We'll cover concepts, technologies, and best practices
2. **Hands-on lab**: You'll apply what you've learned through guided exercises

## Environment Overview

You'll be working with a fully-functional Nutanix environment that includes:

- A Nutanix cluster with Prism Central
- Nutanix Kubernetes Platform (NKP)
- Pre-configured storage and networking
- Access to necessary AI development tools

## What's Next?

Let's get started by connecting to your workshop environment in the [first lab](lab-connect.md).

If you have any questions during the workshop, please don't hesitate to ask the instructors.
