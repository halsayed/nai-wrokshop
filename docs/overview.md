# Workshop Overview

## What You Will Learn

This workshop provides a comprehensive introduction to Generative AI and its practical applications for infrastructure teams. By the end of the day, you will:

- Understand the fundamentals of Large Language Models (LLMs) and their capabilities
- Learn how to deploy and manage AI workloads on Nutanix infrastructure
- Build a functional chatbot application with document understanding capabilities
- Integrate AI tools into your development environment and workflows
- Create automated infrastructure management processes using AI
- Gain hands-on experience with real-world AI applications

## Workshop Structure

Each session consists of two parts:

1. **Theory Component**: We'll cover key concepts, technologies, and best practices
2. **Hands-On Lab**: You'll apply what you've learned through guided practical exercises

## Target Audience

This workshop is designed for:

- Infrastructure administrators and architects
- IT operations teams
- DevOps engineers
- Technical leaders interested in AI adoption

While the workshop focuses on infrastructure concerns, application developers will also find value in understanding how to build and deploy AI-enabled applications.

## Environment Setup

Throughout this workshop, you'll be working with:

- **Nutanix Prism Central (PC)**: For cluster management and visibility
- **Nutanix Kubernetes Platform (NKP)**: For deploying containerized AI workloads
- **Nutanix AI Infrastructure (NAI)**: For running LLMs and AI applications
- **Open-source AI tools**: Including LLM frameworks, chatbot platforms, and workflow automation tools

## Navigation

Use the navigation sidebar to move between different sessions. Each session builds on the previous one, so we recommend following them in order. However, if you're already familiar with certain topics, you can jump ahead to the sections that interest you most.

Ready to begin? Let's start with [Welcome & Introduction](sessions/welcome/index.md).
